{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# a setting for my cluster; ignore it\n",
    "import os\n",
    "os.environ['CUDA_MPS_PIPE_DIRECTORY'] = \"/tmp/nvidia-mps\"\n",
    "os.environ['CUDA_MPS_LOG_DIRECTORY'] = \"/tmp/nvidia-log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 210 ms, total: 1.46 s\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nngp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "random_state = 4623457\n",
    "ndim = 10\n",
    "N_train, N_test, N_pool = 200, 200, 1000\n",
    "layers = [128,64,32]\n",
    "\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (1000, 10) (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import rosen\n",
    "def ans(x):\n",
    "    return rosen(x.T)[:,None]\n",
    "X_train = np.random.random((N_train, ndim))\n",
    "y_train = ans(X_train)\n",
    "\n",
    "X_pool = np.random.random((N_pool, ndim))\n",
    "y_pool = ans(X_pool)\n",
    "\n",
    "X_test = np.random.random((N_test, ndim))\n",
    "y_test = ans(X_test)\n",
    "\n",
    "print('shapes:', X_train.shape, y_train.shape)\n",
    "print('shapes:', X_test.shape, y_test.shape)\n",
    "print('shapes:', X_pool.shape, y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/beardysome/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /media/media_drive/skoltech/nngp_evgeny/nngp.py:98: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/beardysome/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "nn = NN(\n",
    "    ndim = ndim,\n",
    "    random_state = random_state,\n",
    "    layers = layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "# a setting for my cluster; ignore it\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# global init\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100] RMSE train:188.330 test:193.352 val:193.352 patience:3\n",
      "[200] RMSE train:185.401 test:190.416 val:190.416 patience:3\n",
      "[300] RMSE train:173.383 test:178.338 val:178.338 patience:3\n",
      "[400] RMSE train:148.431 test:153.247 val:153.247 patience:3\n",
      "[500] RMSE train:111.355 test:116.008 val:116.008 patience:3\n",
      "[600] RMSE train:77.711 test:82.224 val:82.224 patience:3\n",
      "[700] RMSE train:65.722 test:69.886 val:69.886 patience:3\n",
      "[800] RMSE train:64.474 test:68.452 val:68.452 patience:3\n",
      "[900] RMSE train:64.307 test:68.304 val:68.304 patience:3\n",
      "[1000] RMSE train:64.168 test:68.237 val:68.237 patience:3\n",
      "[1100] RMSE train:64.023 test:68.174 val:68.174 patience:3\n",
      "[1200] RMSE train:63.871 test:68.111 val:68.111 patience:3\n",
      "[1300] RMSE train:63.713 test:68.047 val:68.047 patience:3\n",
      "[1400] RMSE train:63.550 test:67.983 val:67.983 patience:3\n",
      "[1500] RMSE train:63.382 test:67.918 val:67.918 patience:3\n",
      "[1600] RMSE train:63.210 test:67.854 val:67.854 patience:3\n",
      "[1700] RMSE train:63.035 test:67.790 val:67.790 patience:3\n",
      "[1800] RMSE train:62.856 test:67.728 val:67.728 patience:3\n",
      "[1900] RMSE train:62.675 test:67.667 val:67.667 patience:3\n",
      "[2000] RMSE train:62.492 test:67.608 val:67.608 patience:3\n",
      "[2100] RMSE train:62.307 test:67.552 val:67.552 patience:3\n",
      "[2200] RMSE train:62.122 test:67.499 val:67.499 patience:3\n",
      "[2300] RMSE train:61.937 test:67.449 val:67.449 patience:3\n",
      "[2400] RMSE train:61.752 test:67.403 val:67.403 patience:3\n",
      "[2500] RMSE train:61.568 test:67.362 val:67.362 patience:3\n",
      "[2600] RMSE train:61.387 test:67.326 val:67.326 patience:3\n",
      "[2700] RMSE train:61.207 test:67.295 val:67.295 patience:3\n",
      "[2800] RMSE train:61.031 test:67.269 val:67.269 patience:3\n",
      "[2900] RMSE train:60.859 test:67.250 val:67.250 patience:3\n",
      "[3000] RMSE train:60.691 test:67.237 val:67.237 patience:3\n",
      "[3100] RMSE train:60.529 test:67.231 val:67.231 patience:3\n",
      "[3200] RMSE train:60.372 test:67.231 val:67.231 patience:2\n",
      "[3300] RMSE train:60.221 test:67.238 val:67.238 patience:1\n",
      "[3400] RMSE train:60.077 test:67.252 val:67.252 patience:0\n",
      "No patience left at epoch 3400. Early stopping.\n",
      "[1] BEFORE:\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (1000, 10) (1000, 1)\n",
      "[1] AFTER:\n",
      "shapes: (300, 10) (300, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (900, 10) (900, 1)\n",
      "[100] RMSE train:61.275 test:67.689 val:67.689 patience:3\n",
      "[200] RMSE train:61.121 test:67.580 val:67.580 patience:3\n",
      "[300] RMSE train:60.969 test:67.474 val:67.474 patience:3\n",
      "[400] RMSE train:60.822 test:67.372 val:67.372 patience:3\n",
      "[500] RMSE train:60.678 test:67.274 val:67.274 patience:3\n",
      "[600] RMSE train:60.533 test:67.183 val:67.183 patience:3\n",
      "[700] RMSE train:60.391 test:67.092 val:67.092 patience:3\n",
      "[800] RMSE train:60.251 test:67.003 val:67.003 patience:3\n",
      "[900] RMSE train:60.114 test:66.917 val:66.917 patience:3\n",
      "[1000] RMSE train:59.979 test:66.831 val:66.831 patience:3\n",
      "[1100] RMSE train:59.847 test:66.746 val:66.746 patience:3\n",
      "[1200] RMSE train:59.714 test:66.662 val:66.662 patience:3\n",
      "[1300] RMSE train:59.580 test:66.575 val:66.575 patience:3\n",
      "[1400] RMSE train:59.449 test:66.484 val:66.484 patience:3\n",
      "[1500] RMSE train:59.314 test:66.392 val:66.392 patience:3\n",
      "[1600] RMSE train:59.185 test:66.291 val:66.291 patience:3\n",
      "[1700] RMSE train:59.058 test:66.182 val:66.182 patience:3\n",
      "[1800] RMSE train:58.933 test:66.073 val:66.073 patience:3\n",
      "[1900] RMSE train:58.808 test:65.957 val:65.957 patience:3\n",
      "[2000] RMSE train:58.681 test:65.833 val:65.833 patience:3\n",
      "[2100] RMSE train:58.545 test:65.694 val:65.694 patience:3\n",
      "[2200] RMSE train:58.407 test:65.558 val:65.558 patience:3\n",
      "[2300] RMSE train:58.272 test:65.411 val:65.411 patience:3\n",
      "[2400] RMSE train:58.141 test:65.260 val:65.260 patience:3\n",
      "[2500] RMSE train:58.014 test:65.114 val:65.114 patience:3\n",
      "[2600] RMSE train:57.891 test:64.976 val:64.976 patience:3\n",
      "[2700] RMSE train:57.745 test:64.800 val:64.800 patience:3\n",
      "[2800] RMSE train:57.608 test:64.628 val:64.628 patience:3\n",
      "[2900] RMSE train:57.483 test:64.480 val:64.480 patience:3\n",
      "[3000] RMSE train:57.333 test:64.330 val:64.330 patience:3\n",
      "[3100] RMSE train:57.191 test:64.209 val:64.209 patience:3\n",
      "[3200] RMSE train:57.050 test:64.090 val:64.090 patience:3\n",
      "[3300] RMSE train:56.872 test:63.934 val:63.934 patience:3\n",
      "[3400] RMSE train:56.679 test:63.758 val:63.758 patience:3\n",
      "[3500] RMSE train:56.470 test:63.575 val:63.575 patience:3\n",
      "[3600] RMSE train:56.241 test:63.388 val:63.388 patience:3\n",
      "[3700] RMSE train:55.914 test:63.139 val:63.139 patience:3\n",
      "[3800] RMSE train:55.565 test:62.857 val:62.857 patience:3\n",
      "[3900] RMSE train:55.167 test:62.570 val:62.570 patience:3\n",
      "[4000] RMSE train:54.713 test:62.247 val:62.247 patience:3\n",
      "[4100] RMSE train:54.172 test:61.869 val:61.869 patience:3\n",
      "[4200] RMSE train:53.547 test:61.422 val:61.422 patience:3\n",
      "[4300] RMSE train:52.771 test:60.890 val:60.890 patience:3\n",
      "[4400] RMSE train:51.880 test:60.290 val:60.290 patience:3\n",
      "[4500] RMSE train:50.861 test:59.553 val:59.553 patience:3\n",
      "[4600] RMSE train:49.660 test:58.721 val:58.721 patience:3\n",
      "[4700] RMSE train:48.111 test:57.613 val:57.613 patience:3\n",
      "[4800] RMSE train:46.541 test:56.497 val:56.497 patience:3\n",
      "[4900] RMSE train:44.867 test:55.333 val:55.333 patience:3\n",
      "[5000] RMSE train:42.880 test:53.958 val:53.958 patience:3\n",
      "[5100] RMSE train:40.940 test:52.492 val:52.492 patience:3\n",
      "[5200] RMSE train:38.977 test:50.980 val:50.980 patience:3\n",
      "[5300] RMSE train:37.057 test:49.600 val:49.600 patience:3\n",
      "[5400] RMSE train:35.205 test:48.072 val:48.072 patience:3\n",
      "[5500] RMSE train:33.460 test:46.524 val:46.524 patience:3\n",
      "[5600] RMSE train:31.763 test:44.823 val:44.823 patience:3\n",
      "[5700] RMSE train:29.968 test:43.083 val:43.083 patience:3\n",
      "[5800] RMSE train:28.462 test:41.438 val:41.438 patience:3\n",
      "[5900] RMSE train:26.984 test:39.791 val:39.791 patience:3\n",
      "[6000] RMSE train:25.731 test:38.461 val:38.461 patience:3\n",
      "[6100] RMSE train:24.566 test:37.294 val:37.294 patience:3\n",
      "[6200] RMSE train:23.392 test:36.187 val:36.187 patience:3\n",
      "[6300] RMSE train:22.341 test:35.231 val:35.231 patience:3\n",
      "[6400] RMSE train:21.369 test:34.243 val:34.243 patience:3\n",
      "[6500] RMSE train:20.442 test:33.270 val:33.270 patience:3\n",
      "[6600] RMSE train:19.579 test:32.550 val:32.550 patience:3\n",
      "[6700] RMSE train:18.772 test:31.944 val:31.944 patience:3\n",
      "[6800] RMSE train:18.061 test:31.466 val:31.466 patience:3\n",
      "[6900] RMSE train:17.439 test:31.128 val:31.128 patience:3\n",
      "[7000] RMSE train:16.824 test:30.844 val:30.844 patience:3\n",
      "[7100] RMSE train:16.211 test:30.694 val:30.694 patience:3\n",
      "[7200] RMSE train:15.566 test:30.478 val:30.478 patience:3\n",
      "[7300] RMSE train:14.917 test:30.252 val:30.252 patience:3\n",
      "[7400] RMSE train:14.396 test:30.087 val:30.087 patience:3\n",
      "[7500] RMSE train:13.914 test:29.940 val:29.940 patience:3\n",
      "[7600] RMSE train:13.487 test:29.784 val:29.784 patience:3\n",
      "[7700] RMSE train:13.072 test:29.660 val:29.660 patience:3\n",
      "[7800] RMSE train:12.716 test:29.550 val:29.550 patience:3\n",
      "[7900] RMSE train:12.399 test:29.457 val:29.457 patience:3\n",
      "[8000] RMSE train:12.100 test:29.386 val:29.386 patience:3\n",
      "[8100] RMSE train:11.830 test:29.336 val:29.336 patience:3\n",
      "[8200] RMSE train:11.581 test:29.246 val:29.246 patience:3\n",
      "[8300] RMSE train:11.311 test:29.194 val:29.194 patience:3\n",
      "[8400] RMSE train:11.077 test:29.176 val:29.176 patience:3\n",
      "[8500] RMSE train:10.856 test:29.166 val:29.166 patience:3\n",
      "[8600] RMSE train:10.652 test:29.158 val:29.158 patience:3\n",
      "[8700] RMSE train:10.455 test:29.083 val:29.083 patience:3\n",
      "[8800] RMSE train:10.269 test:29.022 val:29.022 patience:3\n",
      "[8900] RMSE train:10.088 test:28.960 val:28.960 patience:3\n",
      "[9000] RMSE train:9.916 test:28.954 val:28.954 patience:3\n",
      "[9100] RMSE train:9.746 test:28.960 val:28.960 patience:2\n",
      "[9200] RMSE train:9.589 test:28.954 val:28.954 patience:1\n",
      "[9300] RMSE train:9.441 test:28.927 val:28.927 patience:3\n",
      "[9400] RMSE train:9.302 test:28.891 val:28.891 patience:3\n",
      "[9500] RMSE train:9.149 test:28.883 val:28.883 patience:3\n",
      "[9600] RMSE train:8.959 test:28.904 val:28.904 patience:2\n",
      "[9700] RMSE train:8.798 test:28.894 val:28.894 patience:1\n",
      "[9800] RMSE train:8.650 test:28.881 val:28.881 patience:3\n",
      "[9900] RMSE train:8.509 test:28.859 val:28.859 patience:3\n",
      "[10000] RMSE train:8.385 test:28.851 val:28.851 patience:3\n",
      "[2] BEFORE:\n",
      "shapes: (300, 10) (300, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (900, 10) (900, 1)\n",
      "[2] AFTER:\n",
      "shapes: (400, 10) (400, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (800, 10) (800, 1)\n",
      "[100] RMSE train:14.239 test:27.902 val:27.902 patience:3\n",
      "[200] RMSE train:13.519 test:27.833 val:27.833 patience:3\n",
      "[300] RMSE train:13.053 test:27.751 val:27.751 patience:3\n",
      "[400] RMSE train:12.667 test:27.658 val:27.658 patience:3\n",
      "[500] RMSE train:12.345 test:27.635 val:27.635 patience:3\n",
      "[600] RMSE train:12.066 test:27.617 val:27.617 patience:3\n",
      "[700] RMSE train:11.824 test:27.594 val:27.594 patience:3\n",
      "[800] RMSE train:11.591 test:27.548 val:27.548 patience:3\n",
      "[900] RMSE train:11.376 test:27.512 val:27.512 patience:3\n",
      "[1000] RMSE train:11.172 test:27.460 val:27.460 patience:3\n",
      "[1100] RMSE train:10.975 test:27.369 val:27.369 patience:3\n",
      "[1200] RMSE train:10.778 test:27.300 val:27.300 patience:3\n",
      "[1300] RMSE train:10.592 test:27.240 val:27.240 patience:3\n",
      "[1400] RMSE train:10.406 test:27.180 val:27.180 patience:3\n",
      "[1500] RMSE train:10.222 test:27.110 val:27.110 patience:3\n",
      "[1600] RMSE train:10.041 test:27.052 val:27.052 patience:3\n",
      "[1700] RMSE train:9.858 test:27.017 val:27.017 patience:3\n",
      "[1800] RMSE train:9.684 test:27.016 val:27.016 patience:3\n",
      "[1900] RMSE train:9.510 test:26.951 val:26.951 patience:3\n",
      "[2000] RMSE train:9.332 test:26.935 val:26.935 patience:3\n",
      "[2100] RMSE train:9.150 test:26.960 val:26.960 patience:2\n",
      "[2200] RMSE train:8.969 test:26.997 val:26.997 patience:1\n",
      "[2300] RMSE train:8.780 test:26.973 val:26.973 patience:0\n",
      "No patience left at epoch 2300. Early stopping.\n",
      "[3] BEFORE:\n",
      "shapes: (400, 10) (400, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (800, 10) (800, 1)\n",
      "[3] AFTER:\n",
      "shapes: (500, 10) (500, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (700, 10) (700, 1)\n",
      "[100] RMSE train:12.144 test:25.035 val:25.035 patience:3\n",
      "[200] RMSE train:11.457 test:24.894 val:24.894 patience:3\n",
      "[300] RMSE train:10.981 test:24.797 val:24.797 patience:3\n",
      "[400] RMSE train:10.590 test:24.669 val:24.669 patience:3\n",
      "[500] RMSE train:10.272 test:24.543 val:24.543 patience:3\n",
      "[600] RMSE train:9.974 test:24.428 val:24.428 patience:3\n",
      "[700] RMSE train:9.710 test:24.278 val:24.278 patience:3\n",
      "[800] RMSE train:9.458 test:24.207 val:24.207 patience:3\n",
      "[900] RMSE train:9.241 test:24.090 val:24.090 patience:3\n",
      "[1000] RMSE train:9.040 test:23.978 val:23.978 patience:3\n",
      "[1100] RMSE train:8.846 test:23.898 val:23.898 patience:3\n",
      "[1200] RMSE train:8.662 test:23.840 val:23.840 patience:3\n",
      "[1300] RMSE train:8.485 test:23.794 val:23.794 patience:3\n",
      "[1400] RMSE train:8.318 test:23.786 val:23.786 patience:3\n",
      "[1500] RMSE train:8.175 test:23.776 val:23.776 patience:3\n",
      "[1600] RMSE train:8.050 test:23.741 val:23.741 patience:3\n",
      "[1700] RMSE train:7.936 test:23.679 val:23.679 patience:3\n",
      "[1800] RMSE train:7.836 test:23.696 val:23.696 patience:2\n",
      "[1900] RMSE train:7.742 test:23.676 val:23.676 patience:3\n",
      "[2000] RMSE train:7.650 test:23.671 val:23.671 patience:3\n",
      "[2100] RMSE train:7.557 test:23.701 val:23.701 patience:2\n",
      "[2200] RMSE train:7.463 test:23.727 val:23.727 patience:1\n",
      "[2300] RMSE train:7.365 test:23.725 val:23.725 patience:0\n",
      "No patience left at epoch 2300. Early stopping.\n",
      "[4] BEFORE:\n",
      "shapes: (500, 10) (500, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (700, 10) (700, 1)\n",
      "[4] AFTER:\n",
      "shapes: (600, 10) (600, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (600, 10) (600, 1)\n",
      "[100] RMSE train:10.950 test:23.812 val:23.812 patience:3\n",
      "[200] RMSE train:10.559 test:23.356 val:23.356 patience:3\n",
      "[300] RMSE train:10.397 test:23.204 val:23.204 patience:3\n",
      "[400] RMSE train:10.272 test:23.036 val:23.036 patience:3\n",
      "[500] RMSE train:10.150 test:23.160 val:23.160 patience:2\n",
      "[600] RMSE train:10.048 test:23.221 val:23.221 patience:1\n",
      "[700] RMSE train:9.960 test:23.156 val:23.156 patience:0\n",
      "No patience left at epoch 700. Early stopping.\n",
      "[5] BEFORE:\n",
      "shapes: (600, 10) (600, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (600, 10) (600, 1)\n",
      "[5] AFTER:\n",
      "shapes: (700, 10) (700, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (500, 10) (500, 1)\n",
      "[100] RMSE train:11.351 test:23.216 val:23.216 patience:3\n",
      "[200] RMSE train:11.143 test:23.032 val:23.032 patience:3\n",
      "[300] RMSE train:10.987 test:23.064 val:23.064 patience:2\n",
      "[400] RMSE train:10.845 test:22.967 val:22.967 patience:3\n",
      "[500] RMSE train:10.733 test:22.706 val:22.706 patience:3\n",
      "[600] RMSE train:10.609 test:22.697 val:22.697 patience:3\n",
      "[700] RMSE train:10.502 test:22.669 val:22.669 patience:3\n",
      "[800] RMSE train:10.403 test:22.651 val:22.651 patience:3\n",
      "[900] RMSE train:10.310 test:22.603 val:22.603 patience:3\n",
      "[1000] RMSE train:10.223 test:22.497 val:22.497 patience:3\n",
      "[1100] RMSE train:10.141 test:22.544 val:22.544 patience:2\n",
      "[1200] RMSE train:10.080 test:22.454 val:22.454 patience:3\n",
      "[1300] RMSE train:9.997 test:22.466 val:22.466 patience:2\n",
      "[1400] RMSE train:9.931 test:22.394 val:22.394 patience:3\n",
      "[1500] RMSE train:9.892 test:22.491 val:22.491 patience:2\n",
      "[1600] RMSE train:9.809 test:22.335 val:22.335 patience:3\n",
      "[1700] RMSE train:9.760 test:22.262 val:22.262 patience:3\n",
      "[1800] RMSE train:9.691 test:22.270 val:22.270 patience:2\n",
      "[1900] RMSE train:9.634 test:22.236 val:22.236 patience:3\n",
      "[2000] RMSE train:9.575 test:22.348 val:22.348 patience:2\n",
      "[2100] RMSE train:9.514 test:22.313 val:22.313 patience:1\n",
      "[2200] RMSE train:9.469 test:22.198 val:22.198 patience:3\n",
      "[2300] RMSE train:9.384 test:22.276 val:22.276 patience:2\n",
      "[2400] RMSE train:9.324 test:22.202 val:22.202 patience:1\n",
      "[2500] RMSE train:9.307 test:22.093 val:22.093 patience:3\n",
      "[2600] RMSE train:9.285 test:22.045 val:22.045 patience:3\n",
      "[2700] RMSE train:9.160 test:22.096 val:22.096 patience:2\n",
      "[2800] RMSE train:9.113 test:22.105 val:22.105 patience:1\n",
      "[2900] RMSE train:9.071 test:22.095 val:22.095 patience:0\n",
      "No patience left at epoch 2900. Early stopping.\n",
      "[6] BEFORE:\n",
      "shapes: (700, 10) (700, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (500, 10) (500, 1)\n",
      "[6] AFTER:\n",
      "shapes: (800, 10) (800, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (400, 10) (400, 1)\n",
      "[100] RMSE train:10.730 test:21.694 val:21.694 patience:3\n",
      "[200] RMSE train:10.528 test:21.477 val:21.477 patience:3\n",
      "[300] RMSE train:10.391 test:21.369 val:21.369 patience:3\n",
      "[400] RMSE train:10.271 test:21.288 val:21.288 patience:3\n",
      "[500] RMSE train:10.171 test:21.139 val:21.139 patience:3\n",
      "[600] RMSE train:10.073 test:21.128 val:21.128 patience:3\n",
      "[700] RMSE train:9.980 test:21.021 val:21.021 patience:3\n",
      "[800] RMSE train:9.895 test:20.944 val:20.944 patience:3\n",
      "[900] RMSE train:9.811 test:20.900 val:20.900 patience:3\n",
      "[1000] RMSE train:9.738 test:20.851 val:20.851 patience:3\n",
      "[1100] RMSE train:9.668 test:20.793 val:20.793 patience:3\n",
      "[1200] RMSE train:9.590 test:20.802 val:20.802 patience:2\n",
      "[1300] RMSE train:9.523 test:20.808 val:20.808 patience:1\n",
      "[1400] RMSE train:9.455 test:20.745 val:20.745 patience:3\n",
      "[1500] RMSE train:9.386 test:20.720 val:20.720 patience:3\n",
      "[1600] RMSE train:9.329 test:20.724 val:20.724 patience:2\n",
      "[1700] RMSE train:9.279 test:20.733 val:20.733 patience:1\n",
      "[1800] RMSE train:9.205 test:20.623 val:20.623 patience:3\n",
      "[1900] RMSE train:9.146 test:20.608 val:20.608 patience:3\n",
      "[2000] RMSE train:9.106 test:20.508 val:20.508 patience:3\n",
      "[2100] RMSE train:9.050 test:20.462 val:20.462 patience:3\n",
      "[2200] RMSE train:8.988 test:20.455 val:20.455 patience:3\n",
      "[2300] RMSE train:8.945 test:20.406 val:20.406 patience:3\n",
      "[2400] RMSE train:8.895 test:20.424 val:20.424 patience:2\n",
      "[2500] RMSE train:8.845 test:20.380 val:20.380 patience:3\n",
      "[2600] RMSE train:8.807 test:20.370 val:20.370 patience:3\n",
      "[2700] RMSE train:8.766 test:20.324 val:20.324 patience:3\n",
      "[2800] RMSE train:8.725 test:20.339 val:20.339 patience:2\n",
      "[2900] RMSE train:8.688 test:20.313 val:20.313 patience:3\n",
      "[3000] RMSE train:8.650 test:20.304 val:20.304 patience:3\n",
      "[3100] RMSE train:8.618 test:20.261 val:20.261 patience:3\n",
      "[3200] RMSE train:8.582 test:20.292 val:20.292 patience:2\n",
      "[3300] RMSE train:8.546 test:20.238 val:20.238 patience:3\n",
      "[3400] RMSE train:8.529 test:20.195 val:20.195 patience:3\n",
      "[3500] RMSE train:8.475 test:20.212 val:20.212 patience:2\n",
      "[3600] RMSE train:8.449 test:20.194 val:20.194 patience:3\n",
      "[3700] RMSE train:8.446 test:20.314 val:20.314 patience:2\n",
      "[3800] RMSE train:8.381 test:20.205 val:20.205 patience:1\n",
      "[3900] RMSE train:8.351 test:20.227 val:20.227 patience:0\n",
      "No patience left at epoch 3900. Early stopping.\n",
      "[7] BEFORE:\n",
      "shapes: (800, 10) (800, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (400, 10) (400, 1)\n",
      "[7] AFTER:\n",
      "shapes: (900, 10) (900, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (300, 10) (300, 1)\n",
      "[100] RMSE train:9.842 test:19.862 val:19.862 patience:3\n",
      "[200] RMSE train:9.692 test:19.827 val:19.827 patience:3\n",
      "[300] RMSE train:9.589 test:19.770 val:19.770 patience:3\n",
      "[400] RMSE train:9.502 test:19.756 val:19.756 patience:3\n",
      "[500] RMSE train:9.438 test:19.728 val:19.728 patience:3\n",
      "[600] RMSE train:9.370 test:19.778 val:19.778 patience:2\n",
      "[700] RMSE train:9.313 test:19.703 val:19.703 patience:3\n",
      "[800] RMSE train:9.244 test:19.739 val:19.739 patience:2\n",
      "[900] RMSE train:9.188 test:19.750 val:19.750 patience:1\n",
      "[1000] RMSE train:9.130 test:19.765 val:19.765 patience:0\n",
      "No patience left at epoch 1000. Early stopping.\n",
      "[8] BEFORE:\n",
      "shapes: (900, 10) (900, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (300, 10) (300, 1)\n",
      "[8] AFTER:\n",
      "shapes: (1000, 10) (1000, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "[100] RMSE train:10.013 test:19.547 val:19.547 patience:3\n",
      "[200] RMSE train:9.901 test:19.513 val:19.513 patience:3\n",
      "[300] RMSE train:9.811 test:19.510 val:19.510 patience:3\n",
      "[400] RMSE train:9.732 test:19.501 val:19.501 patience:3\n",
      "[500] RMSE train:9.668 test:19.487 val:19.487 patience:3\n",
      "[600] RMSE train:9.590 test:19.495 val:19.495 patience:2\n",
      "[700] RMSE train:9.529 test:19.527 val:19.527 patience:1\n",
      "[800] RMSE train:9.465 test:19.515 val:19.515 patience:0\n",
      "No patience left at epoch 800. Early stopping.\n",
      "[9] BEFORE:\n",
      "shapes: (1000, 10) (1000, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "[9] AFTER:\n",
      "shapes: (1100, 10) (1100, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (100, 10) (100, 1)\n",
      "[100] RMSE train:10.757 test:19.438 val:19.438 patience:3\n",
      "[200] RMSE train:10.543 test:19.622 val:19.622 patience:2\n",
      "[300] RMSE train:10.443 test:19.562 val:19.562 patience:1\n",
      "[400] RMSE train:10.347 test:19.576 val:19.576 patience:0\n",
      "No patience left at epoch 400. Early stopping.\n"
     ]
    }
   ],
   "source": [
    "nn.train(\n",
    "    session = sess,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_test = X_test,\n",
    "    y_test = y_test,\n",
    "    X_val = X_test,\n",
    "    y_val = y_test,\n",
    ")\n",
    "\n",
    "rmses = [np.sqrt(mse(nn.predict(sess, data = X_test), y_test))]\n",
    "\n",
    "for al_iteration in range(1, 10):\n",
    "    print(f'[{al_iteration}] BEFORE:')\n",
    "    print('shapes:', X_train.shape, y_train.shape)\n",
    "    print('shapes:', X_test.shape, y_test.shape)\n",
    "    print('shapes:', X_pool.shape, y_pool.shape)\n",
    "    \n",
    "    gpue = nn.get_nngp_UE(sess, X_train, y_train, X_pool, y_pool)\n",
    "    \n",
    "    X_train, y_train, X_pool, y_pool = \\\n",
    "        update_learning_sets(X_train,\n",
    "                             y_train,\n",
    "                             X_pool,\n",
    "                             y_pool,\n",
    "                             gpue,\n",
    "                             sample_size = 100)\n",
    "    \n",
    "    print(f'[{al_iteration}] AFTER:')\n",
    "    print('shapes:', X_train.shape, y_train.shape)\n",
    "    print('shapes:', X_test.shape, y_test.shape)\n",
    "    print('shapes:', X_pool.shape, y_pool.shape)\n",
    "    \n",
    "    nn.train(\n",
    "        session = sess,\n",
    "        X_train = X_train,\n",
    "        y_train = y_train,\n",
    "        X_test = X_test,\n",
    "        y_test = y_test,\n",
    "        X_val = X_test,\n",
    "        y_val = y_test,\n",
    "    )\n",
    "    rmses.append(np.sqrt(mse(nn.predict(sess, data = X_test),\n",
    "            y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67.25156403814879,\n",
       " 28.85082313310023,\n",
       " 26.9729508550653,\n",
       " 23.72526908062341,\n",
       " 23.15615076282674,\n",
       " 22.094892234408363,\n",
       " 20.22693135272602,\n",
       " 19.764543329123125,\n",
       " 19.515263433354697,\n",
       " 19.575532301736178]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201.61533],\n",
       "       [190.08832],\n",
       "       [267.92703]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(sess,\n",
    "           data = X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[183.97308059],\n",
       "       [186.273626  ],\n",
       "       [310.47204144]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([241.29450282, 178.62767736, 176.70902005, 116.13721032,\n",
       "        149.69919447, 168.44082626, 274.13486521, 189.43445536,\n",
       "        175.77393818, 193.04612476, 285.7587523 , 176.24976246,\n",
       "        120.43920411, 252.25571197, 164.48160033,  49.28101007,\n",
       "        191.21251995, 276.40485406, 259.26177001, 154.27310926,\n",
       "         87.08936413, 144.23034991, 125.6479077 , 151.55738739,\n",
       "        145.41873832, 157.08860935, 293.99861717, 226.8078781 ,\n",
       "        173.20591558, 287.37230461, 294.14128571, 125.97612937,\n",
       "        212.02765846, 159.18223435, 118.77298464, 104.94560834,\n",
       "        126.31667623, 142.02853917, 194.64350372, 122.48873608,\n",
       "        162.82253349, 127.87405199, 204.42083344, 240.64953571,\n",
       "        241.77033581, 162.62964201, 210.72693207, 206.14708152,\n",
       "        237.69628055,  99.83513032, 192.31813712, 216.38436548,\n",
       "        133.12171109, 190.23085609, 124.56258256, 141.82176573,\n",
       "        183.80994994, 188.71037284,  96.50622677, 197.99477351,\n",
       "        204.56713186, 186.69139456, 318.76800378, 194.92833848,\n",
       "        217.03035952, 270.20468034, 233.18687196, 113.71997714,\n",
       "        154.57837602, 197.69216992, 149.32710963,  68.57707278,\n",
       "        181.24516038, 218.28769946, 179.33312171, 157.92934502,\n",
       "        187.67337191, 200.12650721, 218.9520584 , 228.02674265,\n",
       "        204.34305666, 144.04222664, 147.31694159, 182.61841931,\n",
       "        122.67369786, 222.15909648, 288.30106643, 150.00300853,\n",
       "         87.96510115, 198.84674027, 206.59039201, 265.54557626,\n",
       "        319.4824209 , 220.33615371, 249.97819792, 246.45558378,\n",
       "        212.02889555, 107.13948928, 160.69271463, 125.05281586]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpue = nn.get_nngp_UE(sess, X_train, y_train, X_pool, y_pool)\n",
    "mcd_ue = nn.get_mcd_UE(sess, X_pool)\n",
    "gpue, mcd_ue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (1100, 10) (1100, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (100, 10) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shapes:', X_train.shape, y_train.shape)\n",
    "print('shapes:', X_test.shape, y_test.shape)\n",
    "print('shapes:', X_pool.shape, y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_pool, y_pool = \\\n",
    "    update_learning_sets(X_train,\n",
    "                         y_train,\n",
    "                         X_pool,\n",
    "                         y_pool,\n",
    "                         gpue,\n",
    "                         sample_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: (1110, 10) (1110, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (90, 10) (90, 1)\n"
     ]
    }
   ],
   "source": [
    "print('shapes:', X_train.shape, y_train.shape)\n",
    "print('shapes:', X_test.shape, y_test.shape)\n",
    "print('shapes:', X_pool.shape, y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
