{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "#### Active learning NNGP experiment\n",
    "We use one set of params for simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.mlp import MLP\n",
    "from dataloader.rosen import RosenData\n",
    "from uncertainty_estimator.nngp import NNGP\n",
    "from sample_selector.eager import EagerSampleSelector\n",
    "from oracle.identity import IdentityOracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'random_state': 4623457,\n",
    "    'n_dim': 10,\n",
    "    'n_train': 200,\n",
    "    'n_test': 200,\n",
    "    'n_pool': 1000,\n",
    "    'layers': [128, 64, 32],\n",
    "    'update_sample_size': 10,\n",
    "    'al_iterations': 10\n",
    "}\n",
    "\n",
    "np.random.seed(config['random_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_shapes(note, *sets):\n",
    "    print(note)\n",
    "    for x, y in sets:\n",
    "        print(\"shapes:\", x.shape, y.shape)\n",
    "\n",
    "# load data\n",
    "X_train, y_train, _, _, X_test, y_test, X_pool, y_pool = RosenData(\n",
    "    config['n_train'], 0, config['n_test'], config['n_pool'], config['n_dim']\n",
    ").dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/beardysome/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /media/media_drive/skoltech/NNGP/model/mlp.py:28: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/beardysome/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Init neural network & tf session\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = MLP(\n",
    "    ndim = config['n_dim'],\n",
    "    random_state = config['random_state'],\n",
    "    layers = config['layers']\n",
    ")\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.allow_growth = True\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=session_config)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0.]]\n",
      "[[-0.1989958  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.       ]]\n",
      "[[-0.1989958  -0.23381726  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319   0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896   0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985  0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985 -0.19535105  0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985 -0.19535105 -0.03851327  0.          0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985 -0.19535105 -0.03851327 -0.2712706   0.          0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985 -0.19535105 -0.03851327 -0.2712706  -0.14656506  0.\n",
      "   0.        ]]\n",
      "[[-0.1989958  -0.23381726 -0.12259002 -0.19776772 -0.06511209 -0.20270069\n",
      "  -0.19741893 -0.27158818 -0.1898319  -0.1916635   0.12811267 -0.20518516\n",
      "   0.15269208 -0.03743003 -0.2722896  -0.09890818 -0.12203766 -0.1751288\n",
      "  -0.04772985 -0.19535105 -0.03851327 -0.2712706  -0.14656506 -0.14105192\n",
      "   0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.00796935,\n",
       "       0.01148678, 0.02160214, 0.        , 0.02019272, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01151447, 0.01062656, 0.        , 0.        , 0.00962229,\n",
       "       0.        , 0.        , 0.        , 0.00463425, 0.        ,\n",
       "       0.00645088, 0.00703455, 0.        , 0.00234648, 0.        ,\n",
       "       0.00901814, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01012011, 0.        , 0.04057716, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02029339, 0.        ,\n",
       "       0.01236252, 0.        , 0.0226581 , 0.00168746, 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = NNGP(model)  # to estimate uncertainties\n",
    "# oracle = IdentityOracle(y_pool)  # generate y for X from pool\n",
    "# sampler = EagerSampleSelector(oracle) # sample X and y from pool by uncertainty estimations\n",
    "\n",
    "estimator.estimate(sess, X_train, y_train, X_pool)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100] RMSE train:191.241 test:188.701 val:188.701 patience:3\n",
      "[200] RMSE train:182.238 test:179.833 val:179.833 patience:3\n",
      "[300] RMSE train:159.539 test:157.416 val:157.416 patience:3\n",
      "[400] RMSE train:118.886 test:117.073 val:117.073 patience:3\n",
      "[500] RMSE train:78.796 test:76.549 val:76.549 patience:3\n",
      "[600] RMSE train:66.604 test:63.424 val:63.424 patience:3\n",
      "[700] RMSE train:65.871 test:62.481 val:62.481 patience:3\n",
      "[800] RMSE train:65.771 test:62.424 val:62.424 patience:3\n",
      "[900] RMSE train:65.674 test:62.407 val:62.407 patience:3\n",
      "[1000] RMSE train:65.572 test:62.392 val:62.392 patience:3\n",
      "[1100] RMSE train:65.465 test:62.378 val:62.378 patience:3\n",
      "[1200] RMSE train:65.354 test:62.365 val:62.365 patience:3\n",
      "[1300] RMSE train:65.240 test:62.353 val:62.353 patience:3\n",
      "[1400] RMSE train:65.122 test:62.343 val:62.343 patience:3\n",
      "[1500] RMSE train:65.001 test:62.335 val:62.335 patience:3\n",
      "[1600] RMSE train:64.879 test:62.330 val:62.330 patience:3\n",
      "[1700] RMSE train:64.754 test:62.326 val:62.326 patience:3\n",
      "[1800] RMSE train:64.628 test:62.325 val:62.325 patience:3\n",
      "[1900] RMSE train:64.500 test:62.328 val:62.328 patience:2\n",
      "[2000] RMSE train:64.372 test:62.333 val:62.333 patience:1\n",
      "[2100] RMSE train:64.243 test:62.341 val:62.341 patience:0\n",
      "No patience left at epoch 2100. Early stopping.\n",
      "[1] BEFORE:\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (1000, 10) (1000, 1)\n",
      "[1] AFTER:\n",
      "shapes: (210, 10) (210, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (990, 10) (1000, 1)\n",
      "[100] RMSE train:65.517 test:62.396 val:62.396 patience:3\n",
      "[200] RMSE train:65.349 test:62.438 val:62.438 patience:2\n",
      "[300] RMSE train:65.183 test:62.485 val:62.485 patience:1\n",
      "[400] RMSE train:65.017 test:62.538 val:62.538 patience:0\n",
      "No patience left at epoch 400. Early stopping.\n",
      "[2] BEFORE:\n",
      "shapes: (210, 10) (210, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (990, 10) (1000, 1)\n",
      "[2] AFTER:\n",
      "shapes: (220, 10) (220, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (980, 10) (1000, 1)\n",
      "[100] RMSE train:64.929 test:62.584 val:62.584 patience:3\n",
      "[200] RMSE train:64.797 test:62.628 val:62.628 patience:2\n",
      "[300] RMSE train:64.665 test:62.674 val:62.674 patience:1\n",
      "[400] RMSE train:64.533 test:62.723 val:62.723 patience:0\n",
      "No patience left at epoch 400. Early stopping.\n",
      "[3] BEFORE:\n",
      "shapes: (220, 10) (220, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (980, 10) (1000, 1)\n",
      "[3] AFTER:\n",
      "shapes: (230, 10) (230, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (970, 10) (1000, 1)\n",
      "[100] RMSE train:64.181 test:62.761 val:62.761 patience:3\n",
      "[200] RMSE train:64.066 test:62.800 val:62.800 patience:2\n",
      "[300] RMSE train:63.952 test:62.840 val:62.840 patience:1\n",
      "[400] RMSE train:63.840 test:62.879 val:62.879 patience:0\n",
      "No patience left at epoch 400. Early stopping.\n",
      "[4] BEFORE:\n",
      "shapes: (230, 10) (230, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (970, 10) (1000, 1)\n",
      "[4] AFTER:\n",
      "shapes: (240, 10) (240, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (960, 10) (1000, 1)\n",
      "[100] RMSE train:63.543 test:62.876 val:62.876 patience:3\n",
      "[200] RMSE train:63.451 test:62.872 val:62.872 patience:3\n",
      "[300] RMSE train:63.354 test:62.861 val:62.861 patience:3\n",
      "[400] RMSE train:63.248 test:62.840 val:62.840 patience:3\n",
      "[500] RMSE train:63.141 test:62.817 val:62.817 patience:3\n",
      "[600] RMSE train:63.036 test:62.793 val:62.793 patience:3\n",
      "[700] RMSE train:62.927 test:62.768 val:62.768 patience:3\n",
      "[800] RMSE train:62.814 test:62.741 val:62.741 patience:3\n",
      "[900] RMSE train:62.704 test:62.720 val:62.720 patience:3\n",
      "[1000] RMSE train:62.591 test:62.697 val:62.697 patience:3\n",
      "[1100] RMSE train:62.477 test:62.675 val:62.675 patience:3\n",
      "[1200] RMSE train:62.357 test:62.647 val:62.647 patience:3\n",
      "[1300] RMSE train:62.228 test:62.611 val:62.611 patience:3\n",
      "[1400] RMSE train:62.091 test:62.563 val:62.563 patience:3\n",
      "[1500] RMSE train:61.935 test:62.482 val:62.482 patience:3\n",
      "[1600] RMSE train:61.784 test:62.392 val:62.392 patience:3\n",
      "[1700] RMSE train:61.627 test:62.310 val:62.310 patience:3\n",
      "[1800] RMSE train:61.441 test:62.205 val:62.205 patience:3\n",
      "[1900] RMSE train:61.271 test:62.099 val:62.099 patience:3\n",
      "[2000] RMSE train:61.086 test:62.027 val:62.027 patience:3\n",
      "[2100] RMSE train:60.891 test:61.901 val:61.901 patience:3\n",
      "[2200] RMSE train:60.694 test:61.801 val:61.801 patience:3\n",
      "[2300] RMSE train:60.478 test:61.671 val:61.671 patience:3\n",
      "[2400] RMSE train:60.253 test:61.523 val:61.523 patience:3\n",
      "[2500] RMSE train:60.014 test:61.401 val:61.401 patience:3\n",
      "[2600] RMSE train:59.729 test:61.231 val:61.231 patience:3\n",
      "[2700] RMSE train:59.428 test:61.022 val:61.022 patience:3\n",
      "[2800] RMSE train:59.039 test:60.771 val:60.771 patience:3\n",
      "[2900] RMSE train:58.600 test:60.474 val:60.474 patience:3\n",
      "[3000] RMSE train:58.142 test:60.127 val:60.127 patience:3\n",
      "[3100] RMSE train:57.617 test:59.736 val:59.736 patience:3\n",
      "[3200] RMSE train:56.970 test:59.210 val:59.210 patience:3\n",
      "[3300] RMSE train:56.247 test:58.642 val:58.642 patience:3\n",
      "[3400] RMSE train:55.379 test:57.959 val:57.959 patience:3\n",
      "[3500] RMSE train:54.203 test:57.071 val:57.071 patience:3\n",
      "[3600] RMSE train:52.898 test:55.965 val:55.965 patience:3\n",
      "[3700] RMSE train:51.279 test:54.585 val:54.585 patience:3\n",
      "[3800] RMSE train:49.467 test:53.007 val:53.007 patience:3\n",
      "[3900] RMSE train:47.278 test:51.193 val:51.193 patience:3\n",
      "[4000] RMSE train:44.664 test:48.890 val:48.890 patience:3\n",
      "[4100] RMSE train:41.635 test:46.359 val:46.359 patience:3\n",
      "[4200] RMSE train:38.497 test:43.681 val:43.681 patience:3\n",
      "[4300] RMSE train:35.595 test:41.319 val:41.319 patience:3\n",
      "[4400] RMSE train:32.588 test:38.943 val:38.943 patience:3\n",
      "[4500] RMSE train:30.001 test:36.964 val:36.964 patience:3\n",
      "[4600] RMSE train:27.509 test:35.113 val:35.113 patience:3\n",
      "[4700] RMSE train:25.026 test:33.587 val:33.587 patience:3\n",
      "[4800] RMSE train:23.035 test:32.263 val:32.263 patience:3\n",
      "[4900] RMSE train:21.353 test:31.116 val:31.116 patience:3\n",
      "[5000] RMSE train:19.600 test:29.986 val:29.986 patience:3\n",
      "[5100] RMSE train:18.170 test:29.196 val:29.196 patience:3\n",
      "[5200] RMSE train:17.009 test:28.468 val:28.468 patience:3\n",
      "[5300] RMSE train:16.037 test:27.845 val:27.845 patience:3\n",
      "[5400] RMSE train:15.188 test:27.313 val:27.313 patience:3\n",
      "[5500] RMSE train:14.409 test:26.796 val:26.796 patience:3\n",
      "[5600] RMSE train:13.697 test:26.316 val:26.316 patience:3\n",
      "[5700] RMSE train:13.029 test:25.900 val:25.900 patience:3\n",
      "[5800] RMSE train:12.388 test:25.503 val:25.503 patience:3\n",
      "[5900] RMSE train:11.836 test:25.138 val:25.138 patience:3\n",
      "[6000] RMSE train:11.327 test:24.829 val:24.829 patience:3\n",
      "[6100] RMSE train:10.830 test:24.561 val:24.561 patience:3\n",
      "[6200] RMSE train:10.389 test:24.341 val:24.341 patience:3\n",
      "[6300] RMSE train:9.989 test:24.162 val:24.162 patience:3\n",
      "[6400] RMSE train:9.624 test:24.043 val:24.043 patience:3\n",
      "[6500] RMSE train:9.234 test:23.922 val:23.922 patience:3\n",
      "[6600] RMSE train:8.889 test:23.813 val:23.813 patience:3\n",
      "[6700] RMSE train:8.591 test:23.654 val:23.654 patience:3\n",
      "[6800] RMSE train:8.328 test:23.535 val:23.535 patience:3\n",
      "[6900] RMSE train:8.096 test:23.415 val:23.415 patience:3\n",
      "[7000] RMSE train:7.872 test:23.353 val:23.353 patience:3\n",
      "[7100] RMSE train:7.666 test:23.344 val:23.344 patience:3\n",
      "[7200] RMSE train:7.437 test:23.356 val:23.356 patience:2\n",
      "[7300] RMSE train:7.246 test:23.331 val:23.331 patience:3\n",
      "[7400] RMSE train:7.071 test:23.359 val:23.359 patience:2\n",
      "[7500] RMSE train:6.915 test:23.369 val:23.369 patience:1\n",
      "[7600] RMSE train:6.771 test:23.379 val:23.379 patience:0\n",
      "No patience left at epoch 7600. Early stopping.\n",
      "[5] BEFORE:\n",
      "shapes: (240, 10) (240, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (960, 10) (1000, 1)\n",
      "[5] AFTER:\n",
      "shapes: (250, 10) (250, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (950, 10) (1000, 1)\n",
      "[100] RMSE train:8.279 test:23.544 val:23.544 patience:3\n",
      "[200] RMSE train:7.962 test:23.584 val:23.584 patience:2\n",
      "[300] RMSE train:7.706 test:23.594 val:23.594 patience:1\n",
      "[400] RMSE train:7.495 test:23.614 val:23.614 patience:0\n",
      "No patience left at epoch 400. Early stopping.\n",
      "[6] BEFORE:\n",
      "shapes: (250, 10) (250, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (950, 10) (1000, 1)\n",
      "[6] AFTER:\n",
      "shapes: (260, 10) (260, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (940, 10) (1000, 1)\n",
      "[100] RMSE train:8.440 test:23.264 val:23.264 patience:3\n",
      "[200] RMSE train:8.040 test:23.236 val:23.236 patience:3\n",
      "[300] RMSE train:7.735 test:23.222 val:23.222 patience:3\n",
      "[400] RMSE train:7.490 test:23.223 val:23.223 patience:2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500] RMSE train:7.287 test:23.211 val:23.211 patience:3\n",
      "[600] RMSE train:7.101 test:23.211 val:23.211 patience:3\n",
      "[700] RMSE train:6.913 test:23.229 val:23.229 patience:2\n",
      "[800] RMSE train:6.745 test:23.230 val:23.230 patience:1\n",
      "[900] RMSE train:6.591 test:23.216 val:23.216 patience:0\n",
      "No patience left at epoch 900. Early stopping.\n",
      "[7] BEFORE:\n",
      "shapes: (260, 10) (260, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (940, 10) (1000, 1)\n",
      "[7] AFTER:\n",
      "shapes: (270, 10) (270, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (930, 10) (1000, 1)\n",
      "[100] RMSE train:7.596 test:22.930 val:22.930 patience:3\n",
      "[200] RMSE train:7.188 test:22.901 val:22.901 patience:3\n",
      "[300] RMSE train:6.894 test:22.940 val:22.940 patience:2\n",
      "[400] RMSE train:6.657 test:22.994 val:22.994 patience:1\n",
      "[500] RMSE train:6.455 test:23.043 val:23.043 patience:0\n",
      "No patience left at epoch 500. Early stopping.\n",
      "[8] BEFORE:\n",
      "shapes: (270, 10) (270, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (930, 10) (1000, 1)\n",
      "[8] AFTER:\n",
      "shapes: (280, 10) (280, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (920, 10) (1000, 1)\n",
      "[100] RMSE train:7.858 test:22.587 val:22.587 patience:3\n",
      "[200] RMSE train:7.387 test:22.503 val:22.503 patience:3\n",
      "[300] RMSE train:7.060 test:22.426 val:22.426 patience:3\n",
      "[400] RMSE train:6.810 test:22.355 val:22.355 patience:3\n",
      "[500] RMSE train:6.596 test:22.298 val:22.298 patience:3\n",
      "[600] RMSE train:6.416 test:22.247 val:22.247 patience:3\n",
      "[700] RMSE train:6.241 test:22.217 val:22.217 patience:3\n",
      "[800] RMSE train:6.089 test:22.204 val:22.204 patience:3\n",
      "[900] RMSE train:5.955 test:22.190 val:22.190 patience:3\n",
      "[1000] RMSE train:5.828 test:22.159 val:22.159 patience:3\n",
      "[1100] RMSE train:5.710 test:22.143 val:22.143 patience:3\n",
      "[1200] RMSE train:5.598 test:22.117 val:22.117 patience:3\n",
      "[1300] RMSE train:5.493 test:22.096 val:22.096 patience:3\n",
      "[1400] RMSE train:5.396 test:22.083 val:22.083 patience:3\n",
      "[1500] RMSE train:5.301 test:22.072 val:22.072 patience:3\n",
      "[1600] RMSE train:5.206 test:22.037 val:22.037 patience:3\n",
      "[1700] RMSE train:5.122 test:22.027 val:22.027 patience:3\n",
      "[1800] RMSE train:5.037 test:22.018 val:22.018 patience:3\n",
      "[1900] RMSE train:4.960 test:22.013 val:22.013 patience:3\n",
      "[2000] RMSE train:4.872 test:22.023 val:22.023 patience:2\n",
      "[2100] RMSE train:4.784 test:22.025 val:22.025 patience:1\n",
      "[2200] RMSE train:4.693 test:22.022 val:22.022 patience:0\n",
      "No patience left at epoch 2200. Early stopping.\n",
      "[9] BEFORE:\n",
      "shapes: (280, 10) (280, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (920, 10) (1000, 1)\n",
      "[9] AFTER:\n",
      "shapes: (290, 10) (290, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (910, 10) (1000, 1)\n",
      "[100] RMSE train:5.191 test:22.017 val:22.017 patience:3\n",
      "[200] RMSE train:4.992 test:21.979 val:21.979 patience:3\n",
      "[300] RMSE train:4.863 test:21.966 val:21.966 patience:3\n",
      "[400] RMSE train:4.760 test:21.951 val:21.951 patience:3\n",
      "[500] RMSE train:4.675 test:21.937 val:21.937 patience:3\n",
      "[600] RMSE train:4.601 test:21.936 val:21.936 patience:3\n",
      "[700] RMSE train:4.534 test:21.927 val:21.927 patience:3\n",
      "[800] RMSE train:4.472 test:21.927 val:21.927 patience:3\n",
      "[900] RMSE train:4.411 test:21.940 val:21.940 patience:2\n",
      "[1000] RMSE train:4.354 test:21.952 val:21.952 patience:1\n",
      "[1100] RMSE train:4.299 test:21.954 val:21.954 patience:0\n",
      "No patience left at epoch 1100. Early stopping.\n",
      "[10] BEFORE:\n",
      "shapes: (290, 10) (290, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (910, 10) (1000, 1)\n",
      "[10] AFTER:\n",
      "shapes: (300, 10) (300, 1)\n",
      "shapes: (200, 10) (200, 1)\n",
      "shapes: (900, 10) (1000, 1)\n",
      "[100] RMSE train:4.726 test:21.840 val:21.840 patience:3\n",
      "[200] RMSE train:4.577 test:21.804 val:21.804 patience:3\n",
      "[300] RMSE train:4.460 test:21.807 val:21.807 patience:2\n",
      "[400] RMSE train:4.369 test:21.814 val:21.814 patience:1\n",
      "[500] RMSE train:4.288 test:21.812 val:21.812 patience:0\n",
      "No patience left at epoch 500. Early stopping.\n"
     ]
    }
   ],
   "source": [
    "model.train(sess, X_train, y_train, X_test, y_test, X_test, y_test)\n",
    "\n",
    "rmses = [np.sqrt(mse(model.predict(sess, data=X_test), y_test))]\n",
    "\n",
    "\n",
    "for al_iteration in range(1, config['al_iterations']+1):\n",
    "    note = f'[{al_iteration}] BEFORE:'\n",
    "    print_shapes(note, (X_train, y_train), (X_test, y_test), (X_pool, y_pool))\n",
    "    \n",
    "    # update pool\n",
    "    uncertainties = estimator.estimate(sess, X_train, y_train, X_pool)\n",
    "    X_train, y_train, X_pool = sampler.update_sets(\n",
    "        X_train, y_train, X_pool, uncertainties, config['update_sample_size']\n",
    "    )\n",
    "    \n",
    "    note = f'[{al_iteration}] AFTER:'\n",
    "    print_shapes(note, (X_train, y_train), (X_test, y_test), (X_pool, y_pool))\n",
    "    \n",
    "    # retrain net\n",
    "    model.train(sess, X_train, y_train, X_test, y_test, X_test, y_test)\n",
    "    rmses.append(np.sqrt(mse(model.predict(sess, data=X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa8a40dc5f8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses, label='NNGP', marker='.')\n",
    "plt.title('RMS Error by active learning iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[269.82272]\n",
      " [236.60335]\n",
      " [228.05836]]\n",
      "[[269.35414184]\n",
      " [199.67728249]\n",
      " [197.7762695 ]]\n"
     ]
    }
   ],
   "source": [
    "# Show some predictions\n",
    "print(model.predict(sess, data = X_test[:3]))\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([160.86413073, 235.44600944, 191.88563576])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some uncertainties\n",
    "estimator.estimate(sess, X_pool)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
